name: Weekly scrape & Deploy Pages

on:
  schedule:
    - cron: '30 0 * * 1'   # Mon 00:30 UTC (~06:00 IST)
  workflow_dispatch: {}

permissions:
  contents: write
  pages: write
  id-token: write

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0            # we will commit & push
          persist-credentials: true # use GITHUB_TOKEN to push

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run scraper (produces site/data/YYYY/YYYY-Wxx.json)
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          SHRM_COVEO_TOKEN: ${{ secrets.SHRM_COVEO_TOKEN }}
        run: |
          python scraper/run.py --week current
          echo "---- After scraper ----"
          ls -lah site || true
          ls -lah site/data || true
          find site/data -type f -name '*.json' -print | sed 's/^/  /' || true

      - name: Configure git identity
        run: |
          git config user.name  "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"

      - name: Commit changes (if any) to repo
        run: |
          git add -A site/data
          if git diff --cached --quiet; then
            echo "No changes to commit."
            exit 0
          fi
          git commit -m "Weekly scrape: $(date -u +'%Y-%m-%dT%H:%M:%SZ')"
          git push
          
      - name: Upload artifact for Pages
        uses: actions/upload-pages-artifact@v3
        with:
          path: site

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
